---
title: "Continuous character models"
author: "Brian C. O'Meara"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

First get packages we need

```{r, eval=TRUE}
install.packages("yearn")
yearn::yearn(ape) #utility fns
yearn::yearn(geiger) #utilty fns
yearn::yearn(OUwie)
```

Now get the tree and data. For these exercises, knowing uncertainty in your measurements can also be important. (remember for homework to change `eval=FALSE` to `eval=TRUE`).

```{r, eval=FALSE}
cont.tree <- read.nexus("MCC_tree.nex")
continuous.data <- read.csv(file="Edit_Dryad_File.csv", stringsAsFactors=FALSE) #death to factors.
```

A function to clean data, make sure taxon names match between tree and data, etc.

```{r, eval=FALSE}
rownames(continuous.data) <- continuous.data[,1]
continuous.data <- continuous.data[,-1, drop=FALSE]
continuous.data <- continuous.data[-1,, drop=FALSE]
ContCleanData <- function(cphy,cdata) {
	treedata(cphy,cdata) #in Geiger is probably my favorite function in R.
}
cleaned.cont.data<-ContCleanData(cont.tree,continuous.data)
```

A function to plot data. Look at `phytools::contMap()`. This is all part of checking: do your data all seem sensible? **LOOK AT IT**.

```{r, eval=FALSE}
library(phytools)
#VisualizeData <- function(phy, data) {
  x<-cleaned.cont.data$data[,1]
  x<-as.numeric(x)
  names(x) <- names(cleaned.cont.data$data[,1])
  phy<-cleaned.cont.data$phy
	obj<-contMap(phy,x)
  #Important here is to LOOK at your data before running it. Any weird values? Does it all make sense? What about your tree? Polytomies?
#}
```

First, start basic. What is the rate of evolution of your trait on the tree?

```{r, eval=FALSE}
BM1 <- geiger::fitContinuous(phy,x,model="BM")
print(paste("The rate of evolution is",BM1$opt$sigsq, "in units of, mm^2/MY"))
```

Important: What are the rates of evolution? In what units?

```{r, eval=FALSE}
OU1 <- fitContinuous(phy,x,model="OU")
par(mfrow=(c(1,2)))
plot(phy, show.tip.label=FALSE)
ou.phy<-rescale(phy,model="OU",OU1$opt$alpha)
plot(ou.phy)
```

How are the trees different?

Compare trees

```{r, eval=FALSE}
AIC.BM1<-BM1$opt$aic
AIC.OU1<-OU1$opt$aic
delta.AIC.BM1<-(BM1$opt$aic)-(BM1$opt$aicc) 
delta.AIC.OU1 <-(OU1$opt$aic)-(OU1$opt$aicc)
```

##OUwie runs##

This takes longer than you may be used to.

We're a bit obsessive about doing multiple starts and in general performing a thorough numerical search. It took you 3+ years to get the data, may as well take an extra five minutes to get an accurate answer

First, we need to assign regimes. The way we do this is with ancestral state estimation of a discrete trait. We can do this using ace() in ape, or similar functions in corHMM or diversitree. Use only one discrete char.

```{r, eval=FALSE}
one.discrete.char <- read.csv(file="ioch_data.csv")
#dont know what's expected here, finding a data set thats also for a discrete character? But I found one. #discrete flower colors. 
rownames(one.discrete.char)<-one.discrete.char[,1]
one.discrete.char<-one.discrete.char[,-1, drop=FALSE]
one.discrete.char<-one.discrete.char[-1,, drop=FALSE]
clean.discrete<-ContCleanData(phy,one.discrete.char)
phy2<-clean.discrete[1]$phy
x2<-clean.discrete[2]$data
reconstruction.info <- ace(x2, phy2, type="discrete", method="ML", CI=TRUE)
best.states<-colnames(reconstruction.info$lik.anc)[apply(reconstruction.info$lik.anc, 1, which.max)]
plot(phy2)
```

Now add these labels to your tree.

```{r, eval=FALSE}
labeled.tree<-phy2$node.label<-best.states
plot(phy2) #did I attach the best states label? or just add it to the list in phy2? is this step correct?
OUwie.data<-read.csv(file="OUwie.Data.csv")
nodeBased.OUMV <- OUwie(phy2,OUwie.data,model="OUMV", simmap.tree=FALSE, diagn=FALSE)
print(nodeBased.OUMV)
```

What do the numbers mean?

Now run all OUwie models:

```{r, eval=FALSE}
RunSingleOUwieModel<-function(model, phy, data){
 	print(paste("Now starting model",model))
 	return(OUwie(phy, data, model)		 	 #simmap.tree=FALSE, diagn=FALSE) I think these are defaults
}
#BM1<-RunSingleOUwieModel("BM1",phy2,OUwie.data) #overwrite object
#BMS<-RunSingleOUwieModel("BMS",phy2,OUwie.data)
#OU1<-RunSingleOUwieModel("OU1",phy2,OUwie.data)
#OUM<-RunSingleOUwieModel("OUM",phy2,OUwie.data)
#OUMV<-RunSingleOUwieModel("OUMV",phy2,OUwie.data)
#OUMA<-RunSingleOUwieModel("OUMA",phy2,OUwie.data)
#OUMVA<-RunSingleOUwieModel("OUMVA",phy2,OUwie.data)
models <- c("BM1","BMS","OU1","OUM","OUMV","OUMA","OUMVA")
results <- lapply(models,RunSingleOUwieModel, phy=phy2, data=OUwie.data) #WOW, just figuerd out the purpose for the lapply here, cool. Only works if you write a function for this purpose. Doesn't work with just OUwie(). 
AICc.values<-sapply(results, "[[", "AICc")
names(AICc.values)<-models
AICc.values<-AICc.values-min(AICc.values)
print(AICc.values) #The best model is the one with smallest AICc score
best<-results[[which.min(AICc.values)]] #store for later
print(best)#prints info on best model #AWESOME, but I think prints a limiting model 
```

We get SE for the optima (see nodeBased.OUMV$theta) but not for the other parameters. Let's see how hard they are to estimate.
First, look at ?OUwie.fixed to see how to calculate likelihood at a single point.

```{r, eval=FALSE}
OU1alpha<-c(0.05070869) #chose OU1 'which wasn't considered the best model' however this model did not contain alpha values in its output. 
OU1sigma.sq<-c(0.56224793)
OU1theta<-results[[3]]$theta[1,1]
OU1.fixed<-OUwie.fixed(phy2,OUwie.data,model="OU1",OU1alpha,OU1sigma.sq,OU1theta) # very odd error 
```

Next, keep all parameters but alpha at their maximum likelihood estimates (better would be to fix just alpha and let the others optimize given this constraint, but this is harder to program for this class). Try a range of alpha values and plot the likelihood against this.

```{r, eval=FALSE}
alpha.values<-seq(from=0.0005, to=0.9995, length.out=50)
```

Keep it simple (and slow) and do a for loop:

```{r, eval=FALSE}
likelihood.values <- rep(NA, length(alpha.values))
for (iteration in sequence(length(alpha.values))) {
	likelihood.values[iteration] <- OUwie.fixed(phy2,OUwie.data, model="OU1", alpha=rep(alpha.values[iteration],2), sigma.sq=results[[3]]$solution[2,], theta=results[[3]]$theta[,1])$loglik
}
likelihood.values #these values are negative (is that odd?) However, if there are both positive and negative eigenvalues, then the objective function is at a saddlepoint and one or several parameters cannot be estimated adequately.
plot(x=alpha.values, y=likelihood.values, xlab="alpha values", ylab="likelihood values", type="l", bty="n")
points(x=results[[3]]$solution[1,1], y=results[[3]]$loglik, pch=16, col="red")
text(x=results[[3]]$solution[1,1], y=results[[3]]$loglik, "unconstrained best", pos=4, col="red")
```

A rule of thumb for confidence for likelihood is all points two log likelihood units worse than the best value. Draw a dotted line on the plot to show this

```{r, eval=FALSE}
plot(x=alpha.values, y=likelihood.values, xlab="alpha values", ylab="likelihood values", type="l", bty="n")
points(x=results[[3]]$solution[1,1], y=results[[3]]$loglik, pch=16, col="red")
text(x=results[[3]]$solution[1,1], y=results[[3]]$loglik, "unconstrained best", pos=4, col="red")
abline(h=-36.0286, lty="dotted") #Two log-likelihood
```

Now, let's try looking at both theta parameters at once, keeping the other parameters at their MLEs

```{r, eval=FALSE}
require("akima")
nreps<-400
theta1.points<-c(results[[3]]$theta[1,1], rnorm(nreps-1, results[[3]]$theta[1,1], 5*results[[3]]$theta[1,2])) #center on optimal value, have extra variance
alpha1.points<-c(results[[3]]$solution[1,1], rnorm(nreps-1, results[[3]]$solution[1,1], 5*results[[3]]$solution[2,1])) #theta2.points<-c(results[[3]]$theta[2,1], rnorm(nreps-1, results[[3]]$theta[2,1], 5*results[[3]]$theta[2,2])) #center on optimal value, have extra variance #sigma or alpha 
likelihood.values.reps<-rep(NA,nreps)
for (iteration in sequence(nreps)){ 
	likelihood.values.reps[iteration] <- OUwie.fixed(phy2,OUwie.data, model="OUMV", alpha=results[[3]]$solution[1,], sigma.sq=results[[3]]$solution[2,], theta=c(theta1.points[iteration], theta2.points[iteration]))$loglik
}
likelihood.values.reps
```


Think of how long that took to do 400 iterations. Now remember how long the search took (longer).

```{r, eval=FALSE}
likelihood.differences<-(-(likelihood.values.reps-max(likelihood.values.reps)))
```

We are interpolating here: contour wants a nice grid. But by centering our simulations on the MLE values, we made sure to sample most thoroughly there

```{r, eval=FALSE}
best<-results[[3]] #this is getting annoying hard coding #OU1 
interpolated.points<-interp(x=theta1.points, y=alpha1.points, z= likelihood.differences, linear=FALSE, extrap=TRUE, xo=seq(min(theta1.points), max(theta1.points), length = 400), yo=seq(min(alpha1.points), max(alpha1.points), length = 400))

#------This contour map is still turning out a little odd-------
contour(interpolated.points, xlim=range(c(theta1.points, alpha1.points)),ylim=range(c(theta1.points, alpha1.points)), xlab="Theta 1", ylab="Alpha 1", levels=c(2,5,10),add=FALSE,lwd=1, bty="n", asp=1)
points(x=best$theta[1,1], y=best$theta[2,1], col="red", pch=16)
points(x=OUwie.data$X[which(OUwie.data$Reg==1)],y=rep(min(c(theta1.points, alpha1.points)), length(which(OUwie.data$Reg==1))), pch=18, col=rgb(0,0,0,.3)) #the tip values in regime 1, plotted along x axis
points(y=OUwie.data$X[which(OUwie.data$Reg==2)],x=rep(min(c(theta1.points, alpha1.points)), length(which(OUwie.data$Reg==2))), pch=18, col=rgb(0,0,0,.3)) #the tip values in regime 2, plotted along y axis
```

The below only works if the discrete trait rate is low, so you have a good chance of estimating where the state is. If it evolves quickly, hard to estimate where the regimes are, so some in regime 1 are incorrectly mapped in regime 2 vice versa. This makes the models more similar than they should be. See Revell 2013, DOI:10.1093/sysbio/sys084 for an exploration of this effect.

```{r, eval=FALSE}
yearn::yearn(phytools)
trait.ordered<-data.frame(trait[,2], trait[,2],row.names=trait[,1])
trait.ordered<- trait.ordered[tree$tip.label,]
z<-trait.ordered[,1]
names(z)<-rownames(trait.ordered)
tree.mapped<-make.simmap(tree,z,model="ER",nsim=1)
leg<-c("black","red")
names(leg)<-c(1,2)
plotSimmap(tree.mapped,leg,pts=FALSE,ftype="off", lwd=1)

simmapBased<-OUwie(tree.mapped,trait,model="OUMV", simmap.tree=TRUE, diagn=FALSE)
print(simmapBased)
print(best)
```

How does this compare to our best model from above? Should they be directly comparable?
